[*] args.cfg_options is None
[*] cfg.get('custom_imports', None) is False
[*] cfg.get('cudnn_benchmark', False) is False
[*]args.work_dir =  ./data/saved_model
[*] cfg.get('train_cfg') =  None
[*] cfg.get('test_cfg') =  None
[*] dataset cfg =  {'type': 'VOCDataset', 'ann_file': './data/VOCdevkit/VOC2007_vis/ImageSets/Main/train.txt', 'img_prefix': './data/VOCdevkit/VOC2007_vis/', 'classes': ('person',), 'pipeline': [{'type': 'LoadImageFromFile'}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'img_scale': (1333, 800), 'keep_ratio': True}, {'type': 'RandomFlip', 'flip_ratio': 0.0}, {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'Pad', 'size_divisor': 32}, {'type': 'DefaultFormatBundle'}, {'type': 'Collect', 'keys': ['img', 'gt_bboxes', 'gt_labels']}]}
[*] total_num =  7294
[*] ds =  {'img_metas': DataContainer({'filename': './data/VOCdevkit/VOC2007_vis/JPEGImages/set04_V001_I01839.jpg', 'ori_filename': 'JPEGImages/set04_V001_I01839.jpg', 'ori_shape': (512, 640, 3), 'img_shape': (800, 1000, 3), 'pad_shape': (800, 1024, 3), 'scale_factor': array([1.5625, 1.5625, 1.5625, 1.5625], dtype=float32), 'flip': False, 'flip_direction': None, 'img_norm_cfg': {'mean': array([123.675, 116.28 , 103.53 ], dtype=float32), 'std': array([58.395, 57.12 , 57.375], dtype=float32), 'to_rgb': True}}), 'img': DataContainer(tensor([[[-1.7925, -1.7925, -1.7925,  ...,  0.0000,  0.0000,  0.0000],
         [-1.7925, -1.7925, -1.8097,  ...,  0.0000,  0.0000,  0.0000],
         [-1.7925, -1.8097, -1.8268,  ...,  0.0000,  0.0000,  0.0000],
         ...,
         [-0.8678, -0.8849, -0.9020,  ...,  0.0000,  0.0000,  0.0000],
         [-1.5357, -1.5528, -1.5528,  ...,  0.0000,  0.0000,  0.0000],
         [-2.1179, -2.1179, -2.1179,  ...,  0.0000,  0.0000,  0.0000]],

        [[-1.6331, -1.6331, -1.6331,  ...,  0.0000,  0.0000,  0.0000],
         [-1.6331, -1.6331, -1.6506,  ...,  0.0000,  0.0000,  0.0000],
         [-1.6506, -1.6506, -1.6681,  ...,  0.0000,  0.0000,  0.0000],
         ...,
         [-0.9503, -0.9678, -0.9853,  ...,  0.0000,  0.0000,  0.0000],
         [-1.5280, -1.5455, -1.5630,  ...,  0.0000,  0.0000,  0.0000],
         [-2.0357, -2.0357, -2.0357,  ...,  0.0000,  0.0000,  0.0000]],

        [[-1.4907, -1.4907, -1.4907,  ...,  0.0000,  0.0000,  0.0000],
         [-1.4907, -1.4907, -1.5081,  ...,  0.0000,  0.0000,  0.0000],
         [-1.4907, -1.5081, -1.5256,  ...,  0.0000,  0.0000,  0.0000],
         ...,
         [-1.2293, -1.2293, -1.2641,  ...,  0.0000,  0.0000,  0.0000],
         [-1.5430, -1.5430, -1.5604,  ...,  0.0000,  0.0000,  0.0000],
         [-1.8044, -1.8044, -1.8044,  ...,  0.0000,  0.0000,  0.0000]]])), 'gt_bboxes': DataContainer(tensor([[ 882.8125,  339.0625,  939.0625,  473.4375],
        [ 948.4375,  337.5000, 1000.0000,  496.8750],
        [ 770.3125,  329.6875,  853.1250,  471.8750]])), 'gt_labels': DataContainer(tensor([0, 0, 0]))}
[*] dataset cfg =  {'type': 'VOCDataset', 'ann_file': './data/VOCdevkit/VOC2007_ir/ImageSets/Main/train.txt', 'img_prefix': './data/VOCdevkit/VOC2007_ir/', 'classes': ('person',), 'pipeline': [{'type': 'LoadImageFromFile'}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'img_scale': (1333, 800), 'keep_ratio': True}, {'type': 'RandomFlip', 'flip_ratio': 0.0}, {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'Pad', 'size_divisor': 32}, {'type': 'DefaultFormatBundle'}, {'type': 'Collect', 'keys': ['img', 'gt_bboxes', 'gt_labels']}]}
[*] total_num =  7294
[*] ds =  {'img_metas': DataContainer({'filename': './data/VOCdevkit/VOC2007_ir/JPEGImages/set04_V001_I01839.jpg', 'ori_filename': 'JPEGImages/set04_V001_I01839.jpg', 'ori_shape': (512, 640, 3), 'img_shape': (800, 1000, 3), 'pad_shape': (800, 1024, 3), 'scale_factor': array([1.5625, 1.5625, 1.5625, 1.5625], dtype=float32), 'flip': False, 'flip_direction': None, 'img_norm_cfg': {'mean': array([123.675, 116.28 , 103.53 ], dtype=float32), 'std': array([58.395, 57.12 , 57.375], dtype=float32), 'to_rgb': True}}), 'img': DataContainer(tensor([[[-2.1008, -2.1008, -2.1008,  ...,  0.0000,  0.0000,  0.0000],
         [-2.1008, -2.1008, -2.1008,  ...,  0.0000,  0.0000,  0.0000],
         [-2.1008, -2.1008, -2.1008,  ...,  0.0000,  0.0000,  0.0000],
         ...,
         [-1.7925, -1.7925, -1.7925,  ...,  0.0000,  0.0000,  0.0000],
         [-1.9638, -1.9638, -1.9638,  ...,  0.0000,  0.0000,  0.0000],
         [-2.1179, -2.1179, -2.1179,  ...,  0.0000,  0.0000,  0.0000]],

        [[-2.0357, -2.0357, -2.0357,  ...,  0.0000,  0.0000,  0.0000],
         [-2.0357, -2.0357, -2.0357,  ...,  0.0000,  0.0000,  0.0000],
         [-2.0357, -2.0357, -2.0357,  ...,  0.0000,  0.0000,  0.0000],
         ...,
         [-1.7381, -1.7381, -1.7381,  ...,  0.0000,  0.0000,  0.0000],
         [-1.8957, -1.8957, -1.8957,  ...,  0.0000,  0.0000,  0.0000],
         [-2.0357, -2.0357, -2.0357,  ...,  0.0000,  0.0000,  0.0000]],

        [[-1.7870, -1.7870, -1.7870,  ...,  0.0000,  0.0000,  0.0000],
         [-1.7870, -1.7870, -1.7870,  ...,  0.0000,  0.0000,  0.0000],
         [-1.7870, -1.7870, -1.7870,  ...,  0.0000,  0.0000,  0.0000],
         ...,
         [-1.4733, -1.4733, -1.4733,  ...,  0.0000,  0.0000,  0.0000],
         [-1.6476, -1.6476, -1.6476,  ...,  0.0000,  0.0000,  0.0000],
         [-1.8044, -1.8044, -1.8044,  ...,  0.0000,  0.0000,  0.0000]]])), 'gt_bboxes': DataContainer(tensor([[ 882.8125,  339.0625,  939.0625,  473.4375],
        [ 948.4375,  337.5000, 1000.0000,  496.8750],
        [ 770.3125,  329.6875,  853.1250,  471.8750]])), 'gt_labels': DataContainer(tensor([0, 0, 0]))}
cfg.gpu_ids[0] =  0
cfg.gpu_ids =  [0]
[*] dataset cfg =  {'type': 'VOCDataset', 'ann_file': './data/VOCdevkit/VOC2007_vis/ImageSets/Main/val.txt', 'img_prefix': './data/VOCdevkit/VOC2007_vis/', 'classes': ('person',), 'pipeline': [{'type': 'LoadImageFromFile'}, {'type': 'MultiScaleFlipAug', 'img_scale': (1333, 800), 'flip': False, 'transforms': [{'type': 'Resize', 'keep_ratio': True}, {'type': 'RandomFlip'}, {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'Pad', 'size_divisor': 32}, {'type': 'ImageToTensor', 'keys': ['img']}, {'type': 'Collect', 'keys': ['img']}]}]}
[*] total_num =  149
[*] ds =  {'img_metas': [DataContainer({'filename': './data/VOCdevkit/VOC2007_vis/JPEGImages/set02_V002_I00281.jpg', 'ori_filename': 'JPEGImages/set02_V002_I00281.jpg', 'ori_shape': (512, 640, 3), 'img_shape': (800, 1000, 3), 'pad_shape': (800, 1024, 3), 'scale_factor': array([1.5625, 1.5625, 1.5625, 1.5625], dtype=float32), 'flip': False, 'flip_direction': None, 'img_norm_cfg': {'mean': array([123.675, 116.28 , 103.53 ], dtype=float32), 'std': array([58.395, 57.12 , 57.375], dtype=float32), 'to_rgb': True}})], 'img': [tensor([[[ 0.9646,  0.9988,  1.0331,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.9646,  1.0159,  1.0502,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.9817,  1.0159,  1.0673,  ...,  0.0000,  0.0000,  0.0000],
         ...,
         [-0.8678, -0.8678, -0.8678,  ...,  0.0000,  0.0000,  0.0000],
         [-1.5357, -1.5357, -1.5357,  ...,  0.0000,  0.0000,  0.0000],
         [-2.1179, -2.1179, -2.1179,  ...,  0.0000,  0.0000,  0.0000]],

        [[ 0.8704,  0.9055,  0.9405,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.8704,  0.9230,  0.9405,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.8880,  0.9230,  0.9580,  ...,  0.0000,  0.0000,  0.0000],
         ...,
         [-0.7052, -0.7052, -0.7052,  ...,  0.0000,  0.0000,  0.0000],
         [-1.4230, -1.4230, -1.4230,  ...,  0.0000,  0.0000,  0.0000],
         [-2.0357, -2.0357, -2.0357,  ...,  0.0000,  0.0000,  0.0000]],

        [[ 1.6465,  1.6814,  1.7163,  ...,  0.0000,  0.0000,  0.0000],
         [ 1.6465,  1.6988,  1.7337,  ...,  0.0000,  0.0000,  0.0000],
         [ 1.6640,  1.6988,  1.7337,  ...,  0.0000,  0.0000,  0.0000],
         ...,
         [-0.4450, -0.4450, -0.4450,  ...,  0.0000,  0.0000,  0.0000],
         [-1.1770, -1.1770, -1.1770,  ...,  0.0000,  0.0000,  0.0000],
         [-1.8044, -1.8044, -1.8044,  ...,  0.0000,  0.0000,  0.0000]]])]}
[*] dataset cfg =  {'type': 'VOCDataset', 'ann_file': './data/VOCdevkit/VOC2007_ir/ImageSets/Main/val.txt', 'img_prefix': './data/VOCdevkit/VOC2007_ir/', 'classes': ('person',), 'pipeline': [{'type': 'LoadImageFromFile'}, {'type': 'MultiScaleFlipAug', 'img_scale': (1333, 800), 'flip': False, 'transforms': [{'type': 'Resize', 'keep_ratio': True}, {'type': 'RandomFlip'}, {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'Pad', 'size_divisor': 32}, {'type': 'ImageToTensor', 'keys': ['img']}, {'type': 'Collect', 'keys': ['img']}]}]}
[*] total_num =  149
[*] ds =  {'img_metas': [DataContainer({'filename': './data/VOCdevkit/VOC2007_ir/JPEGImages/set02_V002_I00281.jpg', 'ori_filename': 'JPEGImages/set02_V002_I00281.jpg', 'ori_shape': (512, 640, 3), 'img_shape': (800, 1000, 3), 'pad_shape': (800, 1024, 3), 'scale_factor': array([1.5625, 1.5625, 1.5625, 1.5625], dtype=float32), 'flip': False, 'flip_direction': None, 'img_norm_cfg': {'mean': array([123.675, 116.28 , 103.53 ], dtype=float32), 'std': array([58.395, 57.12 , 57.375], dtype=float32), 'to_rgb': True}})], 'img': [tensor([[[-0.7993, -0.7993, -0.7993,  ...,  0.0000,  0.0000,  0.0000],
         [-0.7993, -0.7993, -0.7993,  ...,  0.0000,  0.0000,  0.0000],
         [-0.7993, -0.7993, -0.7993,  ...,  0.0000,  0.0000,  0.0000],
         ...,
         [-1.7754, -1.7925, -1.7925,  ...,  0.0000,  0.0000,  0.0000],
         [-1.9638, -1.9638, -1.9638,  ...,  0.0000,  0.0000,  0.0000],
         [-2.1179, -2.1179, -2.1179,  ...,  0.0000,  0.0000,  0.0000]],

        [[-0.7227, -0.7227, -0.7227,  ...,  0.0000,  0.0000,  0.0000],
         [-0.7227, -0.7227, -0.7227,  ...,  0.0000,  0.0000,  0.0000],
         [-0.7227, -0.7227, -0.7227,  ...,  0.0000,  0.0000,  0.0000],
         ...,
         [-1.7206, -1.7206, -1.7381,  ...,  0.0000,  0.0000,  0.0000],
         [-1.8957, -1.8957, -1.8957,  ...,  0.0000,  0.0000,  0.0000],
         [-2.0357, -2.0357, -2.0357,  ...,  0.0000,  0.0000,  0.0000]],

        [[-0.4624, -0.4624, -0.4624,  ...,  0.0000,  0.0000,  0.0000],
         [-0.4624, -0.4624, -0.4624,  ...,  0.0000,  0.0000,  0.0000],
         [-0.4624, -0.4624, -0.4624,  ...,  0.0000,  0.0000,  0.0000],
         ...,
         [-1.4559, -1.4733, -1.4733,  ...,  0.0000,  0.0000,  0.0000],
         [-1.6476, -1.6476, -1.6476,  ...,  0.0000,  0.0000,  0.0000],
         [-1.8044, -1.8044, -1.8044,  ...,  0.0000,  0.0000,  0.0000]]])]}
[*] reading in data_batch_ir_list... 
[*] reading done! Time cost = 181.0s
